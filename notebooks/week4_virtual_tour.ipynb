{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 4 – Virtual Tour / Three.js Export\n",
    "Run the incremental SfM, export a lightweight bundle for the web, and generate a minimal Three.js viewer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('/Users/reyyan/cv-project/assets/wall_b'),\n",
       " PosixPath('/Users/reyyan/cv-project/outputs/reconstruction'))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Locate project root and assets\n",
    "PROJECT_ROOT = Path.cwd().resolve()\n",
    "if not (PROJECT_ROOT / \"assets\").exists() and (PROJECT_ROOT.parent / \"assets\").exists():\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "ASSETS_DIR = PROJECT_ROOT / \"assets\" / \"wall_b\"\n",
    "OUTPUT_DIR = PROJECT_ROOT / \"outputs\" / \"reconstruction\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "ASSETS_DIR, OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'images': 7,\n",
       " 'registered': 7,\n",
       " 'skipped': [],\n",
       " 'points': 908,\n",
       " 'pose_inliers': {0: 0, 1: 0, 2: 22, 3: 56, 4: 36, 5: 71, 6: 89},\n",
       " 'retriangulated': 486}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.multi_view_sfm import run_incremental_sfm\n",
    "\n",
    "result = run_incremental_sfm(\n",
    "    asset_dir=ASSETS_DIR,\n",
    "    detector=\"SIFT\",\n",
    "    ratio_thresh=0.75,\n",
    "    refine=True,\n",
    "    min_correspondences=12,\n",
    "    return_tracks=True,\n",
    ")\n",
    "\n",
    "result.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 7 cameras and 908 points -> /Users/reyyan/cv-project/outputs/reconstruction/virtual_tour_data.json\n",
      "Wrote /Users/reyyan/cv-project/outputs/reconstruction/virtual_tour_viewer.html\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from src.interpolation import rotation_to_quaternion\n",
    "\n",
    "\n",
    "def camera_center(R: np.ndarray, t: np.ndarray) -> list[float]:\n",
    "    return (-R.T @ t).ravel().tolist()\n",
    "\n",
    "\n",
    "bundle = {\n",
    "    \"intrinsics\": result.K.tolist(),\n",
    "    \"images\": [p.name for p in result.image_paths or []],\n",
    "    \"cameras\": [],\n",
    "    \"points\": [],\n",
    "}\n",
    "\n",
    "for idx, cam in enumerate(result.poses):\n",
    "    if not cam.registered:\n",
    "        continue\n",
    "    bundle[\"cameras\"].append(\n",
    "        {\n",
    "            \"index\": idx,\n",
    "            \"image\": cam.image_path.name if cam.image_path else None,\n",
    "            \"R\": cam.R.tolist(),\n",
    "            \"t\": cam.t.ravel().tolist(),\n",
    "            \"center\": camera_center(cam.R, cam.t),\n",
    "            \"quat\": rotation_to_quaternion(cam.R).tolist(),\n",
    "        }\n",
    "    )\n",
    "\n",
    "for pt, rgb in zip(result.points_3d, result.colors_rgb.astype(int)):\n",
    "    bundle[\"points\"].append({\"xyz\": [float(v) for v in pt.tolist()], \"rgb\": [int(c) for c in rgb.tolist()]})\n",
    "\n",
    "json_path = OUTPUT_DIR / \"virtual_tour_data.json\"\n",
    "with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(bundle, f, indent=2)\n",
    "print(f\"Wrote {len(bundle['cameras'])} cameras and {len(bundle['points'])} points -> {json_path}\")\n",
    "\n",
    "html_path = OUTPUT_DIR / \"virtual_tour_viewer.html\"\n",
    "html = \"\"\"<!doctype html>\n",
    "<html lang='en'>\n",
    "<head>\n",
    "  <meta charset='UTF-8'>\n",
    "  <meta name='viewport' content='width=device-width, initial-scale=1.0'>\n",
    "  <title>Virtual Tour Viewer</title>\n",
    "  <style>\n",
    "    body, html { margin: 0; padding: 0; overflow: hidden; background: #0a0a0f; }\n",
    "    #info { position: absolute; top: 12px; left: 12px; color: #f0f0f0; font-family: monospace; z-index: 1; }\n",
    "  </style>\n",
    "  <link rel=\"icon\" href=\"data:,\">\n",
    "  <script type=\"importmap\">{\n",
    "    \"imports\": {\n",
    "      \"three\": \"https://cdn.jsdelivr.net/npm/three@0.160.0/build/three.module.js\",\n",
    "      \"three/examples/jsm/\": \"https://cdn.jsdelivr.net/npm/three@0.160.0/examples/jsm/\"\n",
    "    }\n",
    "  }</script>\n",
    "</head>\n",
    "<body>\n",
    "  <div id='info'>Drag: orbit, Scroll: zoom</div>\n",
    "  <canvas id='c'></canvas>\n",
    "  <script type='module'>\n",
    "    import * as THREE from 'three';\n",
    "    import { OrbitControls } from 'three/examples/jsm/controls/OrbitControls.js';\n",
    "\n",
    "    const canvas = document.getElementById('c');\n",
    "    const renderer = new THREE.WebGLRenderer({canvas, antialias: true});\n",
    "    const scene = new THREE.Scene();\n",
    "    scene.background = new THREE.Color(0x0a0a0f);\n",
    "    const camera = new THREE.PerspectiveCamera(60, 2, 0.1, 5000);\n",
    "    const controls = new OrbitControls(camera, renderer.domElement);\n",
    "\n",
    "    fetch('virtual_tour_data.json').then(r => r.json()).then(data => {\n",
    "      const pts = data.points;\n",
    "      const positions = new Float32Array(pts.length * 3);\n",
    "      const colors = new Float32Array(pts.length * 3);\n",
    "      let i = 0;\n",
    "      for (const p of pts) {\n",
    "        positions[3*i] = p.xyz[0];\n",
    "        positions[3*i+1] = p.xyz[1];\n",
    "        positions[3*i+2] = p.xyz[2];\n",
    "        colors[3*i] = p.rgb[0] / 255;\n",
    "        colors[3*i+1] = p.rgb[1] / 255;\n",
    "        colors[3*i+2] = p.rgb[2] / 255;\n",
    "        i++;\n",
    "      }\n",
    "      const geom = new THREE.BufferGeometry();\n",
    "      geom.setAttribute('position', new THREE.BufferAttribute(positions, 3));\n",
    "      geom.setAttribute('color', new THREE.BufferAttribute(colors, 3));\n",
    "      const mat = new THREE.PointsMaterial({size: 2.2, vertexColors: true, sizeAttenuation: true});\n",
    "      scene.add(new THREE.Points(geom, mat));\n",
    "\n",
    "      const camGeom = new THREE.SphereGeometry(4, 10, 10);\n",
    "      const camMat = new THREE.MeshBasicMaterial({color: 0xffffff});\n",
    "      for (const c of data.cameras) {\n",
    "        const m = new THREE.Mesh(camGeom, camMat);\n",
    "        m.position.set(c.center[0], c.center[1], c.center[2]);\n",
    "        scene.add(m);\n",
    "      }\n",
    "\n",
    "      geom.computeBoundingBox();\n",
    "      const bb = geom.boundingBox;\n",
    "      const center = new THREE.Vector3();\n",
    "      bb.getCenter(center);\n",
    "      const size = new THREE.Vector3();\n",
    "      bb.getSize(size);\n",
    "      const radius = Math.max(size.x, size.y, size.z) * 0.7;\n",
    "      camera.position.set(center.x, center.y, center.z + radius * 1.5);\n",
    "      controls.target.copy(center);\n",
    "      controls.update();\n",
    "    });\n",
    "\n",
    "    function resizeRenderer() {\n",
    "      const w = window.innerWidth;\n",
    "      const h = window.innerHeight;\n",
    "      renderer.setSize(w, h, false);\n",
    "      camera.aspect = w / h;\n",
    "      camera.updateProjectionMatrix();\n",
    "    }\n",
    "    window.addEventListener('resize', resizeRenderer);\n",
    "    resizeRenderer();\n",
    "\n",
    "    function render() {\n",
    "      renderer.render(scene, camera);\n",
    "      requestAnimationFrame(render);\n",
    "    }\n",
    "    render();\n",
    "  </script>\n",
    "</body>\n",
    "</html>\"\"\"\n",
    "\n",
    "with open(html_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(html)\n",
    "print(f\"Wrote {html_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to view the Three.js app\n",
    "1. Run the notebook cells above.\n",
    "2. Start a local server from the reconstruction output folder:\n",
    "   ```bash\n",
    "   cd outputs/reconstruction\n",
    "   python -m http.server 8000\n",
    "   ```\n",
    "3. Open `http://localhost:8000/virtual_tour_viewer.html` in your browser.\n",
    "\n",
    "Controls: drag to orbit, scroll to zoom; the point cloud is colored by the source images and camera centers are shown as white spheres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reyyan//"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Add this to a new cell in your notebook\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')  # Required for the interactive window\n",
    "from src.virtual_tour import VirtualTourViewer\n",
    "\n",
    "# 'result' is the variable holding your SfM output from the previous cells\n",
    "# 'ASSETS_DIR' is the path to your images\n",
    "viewer = VirtualTourViewer(result, ASSETS_DIR)\n",
    "viewer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting trimesh\n",
      "  Downloading trimesh-4.10.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from trimesh) (2.2.6)\n",
      "Downloading trimesh-4.10.1-py3-none-any.whl (737 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m737.0/737.0 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: trimesh\n",
      "Successfully installed trimesh-4.10.1\n"
     ]
    }
   ],
   "source": [
    "#!pip3 install --pre open3d\n",
    "!pip install trimesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Merging with SCALE: 2.0 ---\n",
      "Saved merged point cloud.\n",
      "Saved merged cameras.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import trimesh\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "\n",
    "# ================= CONFIGURATION =================\n",
    "OUTPUT_DIR = Path.cwd().resolve().parent / \"outputs\" / \"reconstruction\"\n",
    "\n",
    "# 1. SCALE: Increase this to push Wall B further away!\n",
    "# If it's too close, try 2.0, 3.0, or even 5.0.\n",
    "SCALE_B = 2.0\n",
    "\n",
    "# 2. POSITION: Keep 0 if you stood in the same spot\n",
    "TRANSLATION_METERS = [7.0, 0.0, -2.0]  \n",
    "\n",
    "# 3. ROTATION: Your L-shape corner\n",
    "ROTATION_Y_DEGREES = -90.0   \n",
    "\n",
    "# 4. SPIN: Keep 180 since that fixed your view\n",
    "CAMERA_SPIN_CORRECTION = 180.0 \n",
    "\n",
    "INPUT_FILES = {\n",
    "    \"ply_a\": OUTPUT_DIR / \"wall_a_dense.ply\",\n",
    "    \"ply_b\": OUTPUT_DIR / \"wall_b_dense.ply\",\n",
    "    \"json_a\": OUTPUT_DIR / \"cameras_wall_a.json\",\n",
    "    \"json_b\": OUTPUT_DIR / \"cameras_wall_b.json\"\n",
    "}\n",
    "OUTPUT_FILES = {\n",
    "    \"ply_merged\": OUTPUT_DIR / \"merged_scene.ply\",\n",
    "    \"json_merged\": OUTPUT_DIR / \"merged_cameras.json\"\n",
    "}\n",
    "# =================================================\n",
    "\n",
    "def get_transform_matrix(degrees, translation):\n",
    "    rads = np.radians(degrees)\n",
    "    c, s = np.cos(rads), np.sin(rads)\n",
    "    R = np.array([[c, 0, s], [0, 1, 0], [-s, 0, c]])\n",
    "    T = np.eye(4)\n",
    "    T[:3, :3] = R\n",
    "    T[:3, 3] = translation\n",
    "    return T\n",
    "\n",
    "def robust_load_and_merge(path):\n",
    "    try:\n",
    "        obj = trimesh.load(str(path))\n",
    "    except Exception as e:\n",
    "        print(f\"FAILED to load {path}: {e}\")\n",
    "        return None\n",
    "    \n",
    "    def extract(o):\n",
    "        v, c = [], []\n",
    "        if isinstance(o, trimesh.Scene):\n",
    "            for g in o.geometry.values():\n",
    "                tv, tc = extract(g)\n",
    "                v.extend(tv); c.extend(tc)\n",
    "        elif isinstance(o, list):\n",
    "            for i in o:\n",
    "                tv, tc = extract(i)\n",
    "                v.extend(tv); c.extend(tc)\n",
    "        elif hasattr(o, 'vertices'):\n",
    "            v.append(np.array(o.vertices))\n",
    "            if hasattr(o, 'colors') and len(o.colors) > 0:\n",
    "                c.append(np.array(o.colors))\n",
    "            elif hasattr(o, 'visual') and hasattr(o.visual, 'vertex_colors') and len(o.visual.vertex_colors) > 0:\n",
    "                c.append(np.array(o.visual.vertex_colors))\n",
    "            else:\n",
    "                c.append(np.ones((len(o.vertices), 4)) * 255)\n",
    "        return v, c\n",
    "\n",
    "    v_list, c_list = extract(obj)\n",
    "    if not v_list: return None\n",
    "    all_v = np.vstack(v_list)\n",
    "    all_c = np.vstack(c_list) if c_list and len(c_list) == len(v_list) else None\n",
    "    return trimesh.PointCloud(vertices=all_v, colors=all_c)\n",
    "\n",
    "def transform_cameras(cameras_list, T, spin_deg=0.0, scale=1.0):\n",
    "    transformed = []\n",
    "    R_transform = T[:3, :3]\n",
    "    t_transform = T[:3, 3]\n",
    "\n",
    "    rads_spin = np.radians(spin_deg)\n",
    "    c_s, s_s = np.cos(rads_spin), np.sin(rads_spin)\n",
    "    R_spin = np.array([[c_s, 0, s_s], [0, 1, 0], [-s_s, 0, c_s]])\n",
    "\n",
    "    for cam in cameras_list:\n",
    "        R_old = np.array(cam['R'])\n",
    "        t_old = np.array(cam['t'])\n",
    "        \n",
    "        # 1. Get Center\n",
    "        C_old = -R_old.T @ t_old\n",
    "        \n",
    "        # 2. APPLY SCALE to Center (Push it away from origin)\n",
    "        C_old = C_old * scale\n",
    "        \n",
    "        # 3. Transform Center\n",
    "        C_new = (R_transform @ C_old) + t_transform\n",
    "        \n",
    "        # 4. Transform Rotation\n",
    "        R_new = R_transform @ R_old\n",
    "        \n",
    "        if abs(spin_deg) > 0.001:\n",
    "            R_new = R_new @ R_spin\n",
    "            \n",
    "        t_new = -R_new @ C_new\n",
    "        \n",
    "        new_cam = deepcopy(cam)\n",
    "        new_cam['R'] = R_new.tolist()\n",
    "        new_cam['t'] = t_new.tolist()\n",
    "        new_cam['center'] = C_new.tolist()\n",
    "        transformed.append(new_cam)\n",
    "        \n",
    "    return transformed\n",
    "\n",
    "def main():\n",
    "    print(f\"--- Merging with SCALE: {SCALE_B} ---\")\n",
    "    \n",
    "    T = get_transform_matrix(ROTATION_Y_DEGREES, TRANSLATION_METERS)\n",
    "    \n",
    "    # Load\n",
    "    pcd_a = robust_load_and_merge(INPUT_FILES[\"ply_a\"])\n",
    "    pcd_b = robust_load_and_merge(INPUT_FILES[\"ply_b\"])\n",
    "    \n",
    "    if pcd_a and pcd_b:\n",
    "        # 1. Scale Point Cloud B\n",
    "        pcd_b.vertices *= SCALE_B\n",
    "        \n",
    "        # 2. Transform Point Cloud B\n",
    "        pcd_b.apply_transform(T)\n",
    "        \n",
    "        merged_v = np.vstack([pcd_a.vertices, pcd_b.vertices])\n",
    "        merged_c = None\n",
    "        if pcd_a.colors is not None and pcd_b.colors is not None:\n",
    "            merged_c = np.vstack([pcd_a.colors, pcd_b.colors])\n",
    "        \n",
    "        final_pcd = trimesh.PointCloud(vertices=merged_v, colors=merged_c)\n",
    "        final_pcd.export(str(OUTPUT_FILES[\"ply_merged\"]))\n",
    "        print(f\"Saved merged point cloud.\")\n",
    "\n",
    "    # Merge Cameras\n",
    "    with open(INPUT_FILES[\"json_a\"], 'r') as f: data_a = json.load(f)\n",
    "    with open(INPUT_FILES[\"json_b\"], 'r') as f: data_b = json.load(f)\n",
    "\n",
    "    cams_a = data_a.get('cameras', [])\n",
    "    cams_b_raw = data_b.get('cameras', [])\n",
    "    \n",
    "    # Pass scale here\n",
    "    cams_b_transformed = transform_cameras(cams_b_raw, T, spin_deg=CAMERA_SPIN_CORRECTION, scale=SCALE_B)\n",
    "    \n",
    "    max_idx = max([c['index'] for c in cams_a]) if cams_a else -1\n",
    "    for i, cam in enumerate(cams_b_transformed):\n",
    "        cam['index'] = max_idx + 1 + i\n",
    "\n",
    "    merged_data = {\n",
    "        \"intrinsics\": data_a.get(\"intrinsics\"),\n",
    "        \"points\": [], \n",
    "        \"cameras\": cams_a + cams_b_transformed\n",
    "    }\n",
    "    \n",
    "    with open(OUTPUT_FILES[\"json_merged\"], 'w') as f:\n",
    "        json.dump(merged_data, f, indent=2)\n",
    "    print(f\"Saved merged cameras.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
